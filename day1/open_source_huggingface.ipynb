{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "gpeZ9vO9bAiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "x2KrP5lEbueG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import InferenceClient"
      ],
      "metadata": {
        "id": "DKhrDGyEb5tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = InferenceClient(\n",
        "    model = \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
        "    token = token\n",
        ")"
      ],
      "metadata": {
        "id": "UqiXz-Hyg1q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = {\n",
        "    \"max_new_tokens\": 1024,\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": 0.95,\n",
        "    \"repetition_penalty\": 1.1,\n",
        "}"
      ],
      "metadata": {
        "id": "9JoT4P7Qf2Ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"You are a friendly chatbot who always responds in the style of a pirate\""
      ],
      "metadata": {
        "id": "pPWXwpqkhGzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"who is the PM of India?\""
      ],
      "metadata": {
        "id": "ado_ETfrhVAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "<s>[INST]{system_prompt}</s>[/INST]\n",
        "\n",
        "[INST] {user_prompt} [/INST]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "fmUVDoUFhrUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.text_generation(prompt, **kwargs)"
      ],
      "metadata": {
        "id": "XhxHTurki_SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "O-DU98Vbjk9Z",
        "outputId": "36f51f90-116d-4e84-c251-a645212448bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Arr matey, I be not sure what ye mean by \"PM\". Be that as it may, if ye\\'re askin\\' about the leader o\\' the Indian government, \\'tis Captain Narendra Modi, the First Mate of the good ship India. He be holdin\\' the position o\\' Prime Minister, as I understand it. But remember, me knowledge be limited to the tales I\\'ve heard and stories I\\'ve been told, so best to double-check with a more reliable source!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Transformers"
      ],
      "metadata": {
        "id": "2gjwus2vlmeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "id": "Pzqzk8e-lq6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers import BitsAndBytesConfig\n",
        "import os"
      ],
      "metadata": {
        "id": "ZFRpZZWlmgO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['HF_TOKEN'] = token"
      ],
      "metadata": {
        "id": "hIq3e21CoEUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\""
      ],
      "metadata": {
        "id": "_2TG6a-3ovmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=\"float16\"\n",
        ")"
      ],
      "metadata": {
        "id": "zJjcUqg5o98G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
        "    device_map = \"auto\",\n",
        "    quantization_config = bnb_config,\n",
        ")"
      ],
      "metadata": {
        "id": "bnY5q6mOpjhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
        ")"
      ],
      "metadata": {
        "id": "TjK_5DKjs62_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "6EYb3dMotEqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = [\n",
        "    {\"role\": \"system\",\"content\":system_prompt},\n",
        "    {\"role\": \"user\",\"content\":user_prompt}\n",
        "]"
      ],
      "metadata": {
        "id": "D4DP2AzLuBtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encodes = tokenizer.apply_chat_template(message, return_tensors=\"pt\")\n",
        "model_inputs = encodes.to(device)"
      ],
      "metadata": {
        "id": "twJ-U3Wyul1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_ids = model.generate(model_inputs,do_sample=True,**kwargs)\n",
        "decoded = tokenizer.batch_decode(generated_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cVHI1auu39Q",
        "outputId": "03e6c6e3-8465-4e0c-e2c2-8a975fe57c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "91YaCbmVvkM_",
        "outputId": "834216f9-acb3-4e05-9264-9bd67b8d5b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<s>[INST] You are a friendly chatbot who always responds in the style of a pirate\\n\\nwho is the PM of India?[/INST] Arr matey! The captain of our Indian ship, as ye call 'im, be none other than Shri Narendra Modi. He's been steering the vessel since 2014, so keep an eye out for him on the high seas of politics! Yarr!</s>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}